# Explainable Alzheimer's Disease Detection from MRI Scans

## Overview

This repository contains partial code from my master's thesis project on explainable Alzheimer's Disease detection using 3D Magnetic Resonance Imaging (MRI) scans. The project introduces an innovative approach to generate visual explanations and textual medical reports for Alzheimer's Disease detection without relying on associated text data or external knowledge sources.

### Key Features

- **Multi-step Classification**: Performs both binary (AD vs. cognitively normal) and ternary (AD, early-stage AD, cognitively normal) classification on MRI data.
- **Visual Explainability**: Utilizes Grad-CAM to generate heatmaps highlighting relevant regions in MRI scans.
- **Brain Atlas Mapping**: Maps generated heatmaps to the Julich Brain Atlas for precise identification of significant brain regions.
- **Structured Data Generation**: Compiles classification results, performance metrics, visual explanations, and brain atlas mapping into a comprehensive JSON format.
- **Natural Language Report Generation**: Employs state-of-the-art Large Language Models to create human-readable medical reports in both English and Italian.
- **Evaluation Framework**: Assesses the performance of language models using metrics such as lexical diversity, readability, coherence, and information coverage.

## Important Note on Code Availability

This repository contains only partial and censored portions of the complete project code. The full methodology and implementation details are currently undergoing the process of submission for publication in a scientific journal. As such, the code in this repository serves as a representative sample of the project structure and core concepts without revealing the novel aspects of the research.

The `notebooks` folder contains sanitized versions of the original notebooks, maintaining the overall structure of the project while protecting the unpublished methodological details.

## Dataset

The dataset used in this project is a combination of the OASIS-3 and OASIS-4 datasets. Due to data privacy and licensing restrictions, the dataset is not included in this repository. Researchers interested in accessing the data can request it through the OASIS Brains website:

[OASIS Brains Dataset Access](https://sites.wustl.edu/oasisbrains/)

## Project Structure

```
explainable-alzheimers-disease-detection/
│
├── data                          <- Dataset of MR images and CSV with numerical features.
│
├── docs                          <- Documentation for the project.
│   └── presentation.pdf
│
├── images                        <- Examples images, screenshots and graphs results.
│
├── json                          <- JSON files containing the descriptors of the XAI framework.
│
├── logs                          <- Logs saved during the training and testing phases.
│
├── notebooks
│   ├── 1-data-exploration.ipynb  <- Explorative data analysys.
│   ├── 2-features-selection.ipynb<- Selection of numerical features.
│   ├── 3-training.ipynb          <- Execution of training phase and results.
│   ├── 4-atlas-mapping.ipynb     <- XAI descriptors extraction.
│   └── 5-explainability.ipynb    <- Testing prompts and descriptors on LLMs.
│
├── outputs                       <- Textual explainability outputs.
│   ├── en
│   └── it
│
├── prompts                       <- Prompts for textual explainability.
│   ├── en
│   └── it
│
├── reports                       <- Saved training and testing splitting and metrics.
|
├── saved                         <- Best models serialization files.
│
├── src
│   ├── helpers                   <- Configuration files and utilities functions.
│   │   ├── config.py
│   │   └── utils.py
│   │
│   ├── models
│   │   ├── densenetmm.py         <- Multi-modal version of a DenseNet CNN.
│   │   └── gradcam.py            <- Grad-CAM algorithm.
│   │
│   ├── modules                   <- Python modules.
│   │   ├── explainability.py
│   │   ├── plotting.py
│   │   ├── postprocessing.py
│   │   ├── preprocessing.py
│   │   └── training.py
│   │
│   └── main.py                  <- Python script for the execution of the whole pipeline.
│
├── .env.example                 <- Environment variables.
├── .gitignore                   <- Specifications of files to be ignored by Git.
├── README.md                    <- The top-level README.
└── requirements.txt             <- Project requirements.
```

## Results

### Example of model input before and after preprocessing
![input](/images/model_input.png)

### Experimental results
![results](/images/metrics.png)

### Grad-CAM heatmap and mask definition
![heatmap](/images/heatmap.png)

## Textual Explainability

For an example of the textual explainability output generated by our framework, please refer to: [Meta-Llama-3-8B-Instruct Explainability Output](explainable-alzheimers-disease-detection/outputs/en/Meta-Llama-3-8B-Instruct.md)

## Resources

Multi-modal model training was carried out on the following resources:

* CPU: 1 x Intel(R) Xeon(R) Gold 5317 CPU @ 3.00GHz (12 cores).
* GPU: 1 x NVIDIA A100 PCIe 80GB.
* RAM: 90 GB.

LLM prompting was carried out on the following resources:

* CPU: 1 x Apple M2 Max (12 cores).
* GPU: 1 x Apple M2 Max (38 cores).
* RAM: 64 GB.

## Acknowledgements

This thesis work was developed in collaboration with [Alberto G. Valerio](https://github.com/albertovalerio) thanks to the support of the [Computational Intelligence Laboratory](https://sites.google.com/site/cilabuniba/home) of the Computer Science Department of the University of Bari Aldo Moro, in the context of the Future Artificial Intelligence Project (spoke 6 - Symbiotic AI), under the Ministry of University and Research program funded by NextGenerationEU.